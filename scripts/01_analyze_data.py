# scripts/01_analyze_data.py
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ä–æ—Å–∞
"""
import pandas as pd
import os
from pathlib import Path

print("="*70)
print("–ê–ù–ê–õ–ò–ó –ò–°–•–û–î–ù–´–• –î–ê–ù–ù–´–•")
print("="*70)

# –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
INPUT_FILE = 'data/raw/survey_results.csv'

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
if not os.path.exists(INPUT_FILE):
    print(f"\n‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª '{INPUT_FILE}' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    print("\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞:")
    print("1. –ü–æ–º–µ—Å—Ç–∏—Ç–µ –≤–∞—à CSV —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É data/raw/")
    print("2. –ü–µ—Ä–µ–∏–º–µ–Ω—É–π—Ç–µ –µ–≥–æ –≤ 'survey_results.csv'")
    print("3. –ò–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é INPUT_FILE –≤ —ç—Ç–æ–º —Å–∫—Ä–∏–ø—Ç–µ")
    exit(1)

print(f"\n‚úì –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {INPUT_FILE}")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("\nüîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
try:
    df = pd.read_csv(INPUT_FILE, low_memory=False)
    print(f"‚úì –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
    exit(1)

# –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
print("\n" + "="*70)
print("üìä –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø")
print("="*70)
print(f"–°—Ç—Ä–æ–∫ (—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤): {len(df):,}")
print(f"–°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns):,}")
print(f"–†–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
print("\n" + "="*70)
print("üìã –°–ü–ò–°–û–ö –í–°–ï–• –°–¢–û–õ–ë–¶–û–í")
print("="*70)
for idx, col in enumerate(df.columns, 1):
    print(f"{idx:3d}. {col}")

# –ü–æ–∏—Å–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
print("\n" + "="*70)
print("üîç –ü–û–ò–°–ö –¢–ï–•–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–• –°–¢–û–õ–ë–¶–û–í")
print("="*70)

tech_columns_patterns = [
    'Language', 'Database', 'Platform', 'Webframe', 'WebFrame'
]

found_tech_columns = []
for col in df.columns:
    for pattern in tech_columns_patterns:
        if pattern.lower() in col.lower():
            found_tech_columns.append(col)
            break

print(f"\n–ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {len(found_tech_columns)}")
for col in found_tech_columns:
    non_null = df[col].notna().sum()
    null_percent = (df[col].isna().sum() / len(df) * 100)
    print(f"\n  ‚Ä¢ {col}")
    print(f"    –ó–∞–ø–æ–ª–Ω–µ–Ω–æ: {non_null:,} ({100-null_percent:.1f}%)")
    print(f"    –ü—Ä–æ–ø—É—Å–∫–æ–≤: {df[col].isna().sum():,} ({null_percent:.1f}%)")
    
    # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
    sample = df[col].dropna().iloc[0] if non_null > 0 else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    if len(str(sample)) > 100:
        sample = str(sample)[:100] + "..."
    print(f"    –ü—Ä–∏–º–µ—Ä: {sample}")

# –ü–æ–∏—Å–∫ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
print("\n" + "="*70)
print("üë• –ü–û–ò–°–ö –î–ï–ú–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–• –°–¢–û–õ–ë–¶–û–í")
print("="*70)

demo_patterns = ['Country', 'Age', 'Ed', 'Gender', 'Employment', 'YearsCode']

found_demo_columns = []
for col in df.columns:
    for pattern in demo_patterns:
        if pattern.lower() in col.lower():
            found_demo_columns.append(col)
            break

print(f"\n–ù–∞–π–¥–µ–Ω–æ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {len(found_demo_columns)}")
for col in found_demo_columns:
    unique_vals = df[col].nunique()
    non_null = df[col].notna().sum()
    null_percent = (df[col].isna().sum() / len(df) * 100)
    
    print(f"\n  ‚Ä¢ {col}")
    print(f"    –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {unique_vals:,}")
    print(f"    –ó–∞–ø–æ–ª–Ω–µ–Ω–æ: {non_null:,} ({100-null_percent:.1f}%)")
    print(f"    –ü—Ä–æ–ø—É—Å–∫–æ–≤: {df[col].isna().sum():,} ({null_percent:.1f}%)")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    if unique_vals <= 20:
        top_values = df[col].value_counts().head(5)
        print(f"    –¢–æ–ø-5 –∑–Ω–∞—á–µ–Ω–∏–π:")
        for val, count in top_values.items():
            print(f"      - {val}: {count:,} ({count/len(df)*100:.1f}%)")

# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
print("\n" + "="*70)
print("üîç –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô")
print("="*70)

missing_data = pd.DataFrame({
    'Column': df.columns,
    'Missing_Count': df.isnull().sum(),
    'Missing_Percent': (df.isnull().sum() / len(df) * 100).round(2)
})

missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values(
    'Missing_Percent', ascending=False
)

if len(missing_data) > 0:
    print(f"\n–°—Ç–æ–ª–±—Ü–æ–≤ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: {len(missing_data)}")
    print("\n–¢–æ–ø-10 —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤:")
    print(missing_data.head(10).to_string(index=False))
else:
    print("\n‚úì –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è ResponseId
print("\n" + "="*70)
print("üîë –ü–†–û–í–ï–†–ö–ê –ò–î–ï–ù–¢–ò–§–ò–ö–ê–¢–û–†–ê –†–ï–°–ü–û–ù–î–ï–ù–¢–ê")
print("="*70)

id_columns = ['ResponseId', 'RespondentId', 'Respondent', 'ID', 'id']
found_id = None

for col in id_columns:
    if col in df.columns:
        found_id = col
        break

if found_id:
    print(f"‚úì –ù–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü ID: '{found_id}'")
    print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {df[found_id].nunique():,}")
    print(f"  –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {df[found_id].duplicated().sum():,}")
    
    if df[found_id].nunique() == len(df):
        print(f"  ‚úì –í—Å–µ ID —É–Ω–∏–∫–∞–ª—å–Ω—ã")
    else:
        print(f"  ‚ö†Ô∏è –ï—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã ID!")
else:
    print("‚ö†Ô∏è –°—Ç–æ–ª–±–µ—Ü —Å ID —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    print("   –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
print("\n" + "="*70)
print("üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –û–¢–ß–ï–¢–ê")
print("="*70)

report_path = 'data/processed/data_analysis_report.txt'
Path('data/processed').mkdir(exist_ok=True)

with open(report_path, 'w', encoding='utf-8') as f:
    f.write("="*70 + "\n")
    f.write("–û–¢–ß–ï–¢ –ü–û –ê–ù–ê–õ–ò–ó–£ –î–ê–ù–ù–´–•\n")
    f.write("="*70 + "\n\n")
    f.write(f"–§–∞–π–ª: {INPUT_FILE}\n")
    f.write(f"–°—Ç—Ä–æ–∫: {len(df):,}\n")
    f.write(f"–°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns):,}\n\n")
    
    f.write("–¢–ï–•–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ï –°–¢–û–õ–ë–¶–´:\n")
    f.write("-"*70 + "\n")
    for col in found_tech_columns:
        f.write(f"  ‚Ä¢ {col}\n")
    
    f.write("\n\n–î–ï–ú–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ï –°–¢–û–õ–ë–¶–´:\n")
    f.write("-"*70 + "\n")
    for col in found_demo_columns:
        f.write(f"  ‚Ä¢ {col}\n")
    
    if len(missing_data) > 0:
        f.write("\n\n–ü–†–û–ü–£–©–ï–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø:\n")
        f.write("-"*70 + "\n")
        f.write(missing_data.head(20).to_string(index=False))

print(f"‚úì –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

# –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
print("\n" + "="*70)
print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
print("="*70)
print(f"\nüìä –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞:")
print(f"  ‚Ä¢ –†–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤: {len(df):,}")
print(f"  ‚Ä¢ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {len(found_tech_columns)}")
print(f"  ‚Ä¢ –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤: {len(found_demo_columns)}")
print(f"  ‚Ä¢ –°—Ç–æ–ª–±—Ü–æ–≤ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: {len(missing_data)}")
print(f"  ‚Ä¢ ID —Å—Ç–æ–ª–±–µ—Ü: {found_id if found_id else '–ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω'}")

print("\nüìù –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:")
print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/02_prepare_data.py")
print("="*70)